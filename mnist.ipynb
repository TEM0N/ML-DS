{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "KOpXZ7oYabop",
        "outputId": "3e2ec5e2-9115-48ce-fd2d-f77341c08859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (1797, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "\n",
        "print(\"Shape:\", X.shape)  # (1797, 64)\n",
        "\n",
        "# Визуализация первых цифр\n",
        "fig, axes = plt.subplots(1, 5, figsize=(10, 3))\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(digits.images[i], cmap=\"gray\")\n",
        "    ax.set_title(f\"Label: {y[i]}\")\n",
        "    ax.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression baseline\n",
        "logreg = LogisticRegression(max_iter=5000)\n",
        "logreg.fit(X_train, y_train)\n",
        "preds = logreg.predict(X_test)\n",
        "\n",
        "print(\"LogReg Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlqfLOiYhO69",
        "outputId": "c9088bb4-b9e1-4fef-f04b-fe23d3e29c31"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogReg Accuracy: 0.975\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       0.97      1.00      0.98        28\n",
            "           2       1.00      1.00      1.00        33\n",
            "           3       0.97      0.97      0.97        34\n",
            "           4       1.00      0.98      0.99        46\n",
            "           5       0.92      0.96      0.94        47\n",
            "           6       0.97      0.97      0.97        35\n",
            "           7       1.00      0.97      0.99        34\n",
            "           8       0.97      0.97      0.97        30\n",
            "           9       0.97      0.95      0.96        40\n",
            "\n",
            "    accuracy                           0.97       360\n",
            "   macro avg       0.98      0.98      0.98       360\n",
            "weighted avg       0.98      0.97      0.98       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"RandomForest Accuracy:\", accuracy_score(y_test, rf.predict(X_test)))\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=6, random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\")\n",
        "xgb.fit(X_train, y_train)\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6k1fuFfhW4f",
        "outputId": "f7961532-9ca2-4443-9089-f74792ec3516"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest Accuracy: 0.9694444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:22:50] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Преобразуем данные в тензоры\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_ds = TensorDataset(X_train_t, y_train_t)\n",
        "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "\n",
        "# Простая сеть: вход (64) → скрытый слой (128) → выход (10 классов)\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "model = SimpleNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Обучение\n",
        "for epoch in range(10):\n",
        "    for xb, yb in train_dl:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Оценка\n",
        "with torch.no_grad():\n",
        "    preds_test = model(X_test_t)\n",
        "    acc = (preds_test.argmax(dim=1) == y_test_t).float().mean()\n",
        "    print(\"Neural Network Accuracy:\", acc.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTFtiaZwhc3l",
        "outputId": "4acf91fb-75ec-4aca-ed8b-441d7b9f2f92"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.8037\n",
            "Epoch 2, Loss: 0.5030\n",
            "Epoch 3, Loss: 0.1369\n",
            "Epoch 4, Loss: 0.1682\n",
            "Epoch 5, Loss: 0.1163\n",
            "Epoch 6, Loss: 0.1295\n",
            "Epoch 7, Loss: 0.1358\n",
            "Epoch 8, Loss: 0.1509\n",
            "Epoch 9, Loss: 0.0401\n",
            "Epoch 10, Loss: 0.0379\n",
            "Neural Network Accuracy: 0.9777777791023254\n"
          ]
        }
      ]
    }
  ]
}