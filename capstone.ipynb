{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOpXZ7oYabop",
        "outputId": "184794a0-a937-41dd-aff9-259c4048b453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "LogReg Accuracy: 0.9259\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6239 - loss: 17.4492 - val_accuracy: 0.8353 - val_loss: 0.6521\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7518 - loss: 0.9467 - val_accuracy: 0.8870 - val_loss: 0.4749\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.6941 - val_accuracy: 0.9103 - val_loss: 0.3883\n",
            "Epoch 4/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.5638 - val_accuracy: 0.9285 - val_loss: 0.3508\n",
            "Epoch 5/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8660 - loss: 0.4794 - val_accuracy: 0.9300 - val_loss: 0.3217\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.4768\n",
            "MLP Accuracy: 0.9178000092506409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 98ms/step - accuracy: 0.7581 - loss: 0.7629 - val_accuracy: 0.9808 - val_loss: 0.0660\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 94ms/step - accuracy: 0.9533 - loss: 0.1590 - val_accuracy: 0.9860 - val_loss: 0.0536\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 94ms/step - accuracy: 0.9637 - loss: 0.1233 - val_accuracy: 0.9870 - val_loss: 0.0448\n",
            "Epoch 4/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 95ms/step - accuracy: 0.9702 - loss: 0.0983 - val_accuracy: 0.9888 - val_loss: 0.0387\n",
            "Epoch 5/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 92ms/step - accuracy: 0.9765 - loss: 0.0805 - val_accuracy: 0.9895 - val_loss: 0.0380\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9871 - loss: 0.0382\n",
            "CNN Accuracy: 0.9889000058174133\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Загрузка данных\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Logistic Regression (baseline)\n",
        "x_train_flat = x_train.reshape(-1, 28*28) / 255.0\n",
        "x_test_flat = x_test.reshape(-1, 28*28) / 255.0\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(x_train_flat, y_train)\n",
        "print(\"LogReg Accuracy:\", accuracy_score(y_test, log_reg.predict(x_test_flat)))\n",
        "\n",
        "# 2. MLP\n",
        "mlp = Sequential([\n",
        "    Flatten(input_shape=(28,28)),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dropout(0.3),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "mlp.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "mlp.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.1)\n",
        "mlp_acc = mlp.evaluate(x_test, y_test)[1]\n",
        "print(\"MLP Accuracy:\", mlp_acc)\n",
        "\n",
        "# 3. CNN\n",
        "x_train_cnn = x_train.reshape(-1,28,28,1)/255.0\n",
        "x_test_cnn = x_test.reshape(-1,28,28,1)/255.0\n",
        "cnn = Sequential([\n",
        "    Conv2D(32, (3,3), activation=\"relu\", input_shape=(28,28,1)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Conv2D(64, (3,3), activation=\"relu\"),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "cnn.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "cnn.fit(x_train_cnn, y_train, epochs=5, batch_size=128, validation_split=0.1)\n",
        "cnn_acc = cnn.evaluate(x_test_cnn, y_test)[1]\n",
        "print(\"CNN Accuracy:\", cnn_acc)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}